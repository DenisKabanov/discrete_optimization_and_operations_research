{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Написать эвристический алгоритм для поиска максимального независимого взвешенного (по вершинам) множества в графе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как \"независимое множество графа G = клика в дополнении графа G\", то задачу можно переформулировать в поиск максимальной взвешенной клики в дополнении графа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Настройки/Гиперпараметры/Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # для быстрой работы с массивами\n",
    "import pandas as pd # для вывода таблицы (v 2.1.1)\n",
    "import random # для рандомизированного алгоритма\n",
    "import time # для подсчёта времени работы\n",
    "import csv # для сохранения ответов\n",
    "import math # для округления чисел в большую сторону (ceil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = 10 # число запусков для усреднения времени\n",
    "iterations = 1000 # сколько итераций должно пройти без улучшения ответа, чтобы алгоритм вернул текущий лучший\n",
    "\n",
    "eps = 0.0001 # с какой погрешностью считать, что числа одинаковые\n",
    "\n",
    "impact_degree = 10 # степень влиянися количества соседей у вершины на вероятность её выбора в клику\n",
    "impact_weight = 1 # степень влиянися веса вершины на вероятность её выбора в клику\n",
    "\n",
    "data_path = \"./data/\" # путь до папки с входными данными\n",
    "solutions_path = \"./solutions/\" # путь, куда будут сохраняться посчитанные решения\n",
    "\n",
    "files = [\"brock200_1\", \"brock200_2\", \"brock200_3\", \"brock200_4\", \"c-fat200-1\", \"c-fat200-2\", \"c-fat200-5\", \"c-fat500-1\", \"c-fat500-10\", \"c-fat500-2\", \"c-fat500-5\", \"C125.9\", \"gen200_p0.9_44\", \"gen200_p0.9_55\",  \"johnson8-2-4\",  \"johnson8-4-4\", \"johnson16-2-4\", \"hamming6-2\", \"hamming6-4\", \"hamming8-2\", \"hamming8-4\", \"keller4\", \"MANN_a9\", \"MANN_a27\", \"MANN_a45\", \"p_hat300-1\", \"p_hat300-2\", \"p_hat300-3\", \"san200_0.7_1\", \"san200_0.7_2\", \"san200_0.9_1\", \"san200_0.9_2\", \"san200_0.9_3\", \"sanr200_0.7\"] # все файлы, на которых должен быть протестирован код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вспомогательные функции, не участвующие в работе алгоритма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_complement_edges(edges: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Функция, возвращающая список смежности дополнения графа.\\n\n",
    "    Parameters:\n",
    "        * edges: словарь смежных вершинам вершин, описывающий граф (по i-му индексу находится set со смежными i-ой вершине вершинами)\\n\n",
    "    Returns:\n",
    "        * dict: словарь смежных вершинам вершин, описывающий дополнение графа\n",
    "    \"\"\"\n",
    "    num_vertices = len(edges.keys()) # число вершин в графе\n",
    "    all_vertices = set(range(num_vertices)) # set из всех вершин\n",
    "\n",
    "    edges_complement = {} # словарь как список смежности дополнения графа\n",
    "    for v in edges.keys(): # идём по вершинам-ключам в списке смежности для изначального графа\n",
    "        edges_complement[v] = all_vertices - edges[v] - set([v]) # оставляем только те вершины, которые ранее не были смежны с вершиной v (саму вершину v тоже убираем)\n",
    "    return edges_complement # возвращаем словарь смежных вершинам вершин, описывающий дополнение графа\n",
    "\n",
    "\n",
    "def check_solution(edges_complement: dict, weights: list, solution, eps=0.0001) -> None:\n",
    "    \"\"\"\n",
    "    Функция для проверка полученного лучшего решения.\\n\n",
    "    Parameters:\n",
    "        * edges_complement: словарь смежных вершинам вершин, описывающий дополнение графа\n",
    "        * weights: список весов вершин, где index — номер вершины\n",
    "        * solution: решение в формате [вес независимого множества, [вершины независимого множества]]\n",
    "        * eps: с какой погрешностью считать, что числа одинаковые\\n\n",
    "    Returns:\n",
    "        * None: выкидывает исключение, если в решении есть ошибки\n",
    "    \"\"\"\n",
    "    check_weight_sum = 0 # проверочная сумма весов вершин\n",
    "    for v in solution[1]: # идём по номерам вершин независимого множества\n",
    "        check_weight_sum += weights[v] # увеличиваем проверочную сумму весов вершин на значение веса рассматриваемой вершины\n",
    "\n",
    "    if not (check_weight_sum - eps <= solution[0] <= check_weight_sum + eps): # проверка соответствия веса, полученного алгоритмом\n",
    "        raise Exception(\"Weight is incorrect!\") # выкидываем ошибку, если веса не сошлись\n",
    "\n",
    "    for i in range(len(solution[1])-1): # идём по вершинам и проверяем, смежны ли она со всеми остальными вершинами в найденной клике ДОПОЛНЕНИЯ графа\n",
    "        for j in range(i+1, len(solution[1])): # идём по последующим вершинам в клике\n",
    "            if solution[1][j] not in edges_complement[solution[1][i]]: # проверяем наличие ребра между вершинами\n",
    "                raise Exception(f\"Nodes {i} and {j} connected!\") # выкидываем ошибку, если вершины в изначальном графе были смежными (в дополнении между ними не должно быть ребра)\n",
    "\n",
    "\n",
    "def transform_solution(solution, round_numbers=2) -> list:\n",
    "    \"\"\"\n",
    "    Функция для преобразования ответа, чтобы номера вершин шли не с 0, а с 1 и по порядку.\\n\n",
    "    Parameters:\n",
    "        * solution: решение в формате [вес независимого множества, [вершины независимого множества]]\n",
    "        * round_numbers: число сохраняемых чисел после запятой\\n\n",
    "    Returns:\n",
    "        * list: решение в формате [вес независимого множества, [отсортированные инкрементированные вершины независимого множества]]\n",
    "    \"\"\"\n",
    "    for i in range(len(solution[1])): # идём по числу вершин в решении\n",
    "        solution[1][i] += 1 # инкрементируем номер вершины (чтобы они шли не с 0, а с 1)\n",
    "    return [round(solution[0], round_numbers), sorted(solution[1])] # возвращаем решение, попутно отсортировав инкрементированные вершины и округляя до round_numbers чисел после запятой\n",
    "\n",
    "\n",
    "def save_solution(dataset, solution: dict) -> None:\n",
    "    \"\"\"\n",
    "    Функция для сохранения лучших ответов.\\n\n",
    "    Parameters:\n",
    "        * dataset: название тест-кейса\n",
    "        * solution: словарь для тест-кейса с решениями в формате {\"time\": время на подсчёт, \"weight\": вес получившегося независимого множества, \"independent_set\": [вершины, входящие в независимое множество]}\\n\n",
    "    Returns:\n",
    "        * None: сохраняет решение\n",
    "    \"\"\"\n",
    "    with open(f\"{solutions_path}{dataset}.csv\", 'w', newline='') as file: # открываем файл для чистой записи\n",
    "        writer = csv.writer(file) # создаём объект для записи\n",
    "        writer.writerow([solution[\"weight\"]]) # сохраняем размер клики (writerow — сохранение одного элемента в строку)\n",
    "        writer.writerows([solution[\"independent_set\"]]) # сохраняем вершины клики (writerows — сохранение итерационных данных по типу списка в строку)\n",
    "        writer.writerow([solution[\"time\"]]) # сохраняем время работы  (writerow — сохранение одного элемента в строку)\n",
    "\n",
    "\n",
    "def show_results(solutions: dict) -> None: # solutions - словарь всех полученных ответов\n",
    "    \"\"\"\n",
    "    Функция для вывода таблицы результатов.\\n\n",
    "    Parameters:\n",
    "        * solutions: словарь решений в формате {\"название датасета\": {\"time\": время на подсчёт, \"weight\": вес получившегося независимого множества, \"independent_set\": [вершины, входящие в независимое множество]}, ...}\\n\n",
    "    Returns:\n",
    "        * None: строит таблицу с полученными ответами\n",
    "    \"\"\"\n",
    "    table = pd.DataFrame(data = [], columns=[\"Instance\", \"Time, sec\", \"Weight\", \"Independent vertices\"]) # создаём pandas таблицу\n",
    "    for dataset in solutions.keys(): # идём по тест-кейсам\n",
    "        testcase = pd.DataFrame(data = [[dataset, solutions[dataset][\"time\"], solutions[dataset][\"weight\"], solutions[dataset][\"independent_set\"]]], columns=[\"Instance\", \"Time, sec\", \"Weight\", \"Independent vertices\"]) # создаём \"новую\" таблицу для тест-кейса\n",
    "        table = pd.concat([table, testcase], ignore_index=True) # объединяем таблицы\n",
    "    display(table.style.hide()) # скрываем отображение индексов строк таблицы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Считывание данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {} \n",
    "# data - словарь вида \n",
    "# {\"название датасета\" : \n",
    "#     {\"vertex_num\": число вершин, \n",
    "#      \"edge_num\": число рёбер, \n",
    "#      \"edges\": \n",
    "#         {словарь вида вершина - set смежных ей вершин}\n",
    "#     }\n",
    "#  ...\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    data[file] = {\"vertex_num\": None, \"edge_num\": None, \"edges\": {}}\n",
    "    with open(f\"{data_path}{file}.clq\", \"r\") as f: # открываем файл для чтения\n",
    "        for row in f: # проходим по строкам\n",
    "            if row[0] == \"c\": # если строка начинается с буквы \"c\" - это комментарий, пропускае строку\n",
    "                continue\n",
    "            elif row[0] == \"p\": # если строка начинается с буквы \"p\" - это описание проблемы, берём из этой строки число вершин и рёбер (последние два числа)\n",
    "                data[file][\"vertex_num\"], data[file][\"edge_num\"] = int(row.split()[-2]), int(row.split()[-1])\n",
    "            elif row[0] == \"e\": # если строка начинается с буквы \"p\" - это вершины, между которыми есть ребро\n",
    "                v1, v2 = int(row.split()[-2]) - 1, int(row.split()[-1]) - 1 # запоминаем вершины (-1, чтобы не было мороки с индексацией)\n",
    "\n",
    "                # добавляем связь вершины v1 с v2\n",
    "                if v1 not in data[file][\"edges\"].keys(): # если это первое упоминание вершины v1 - создадим для неё set с указанием v2\n",
    "                    data[file][\"edges\"][v1] = {v2}\n",
    "                elif v2 not in data[file][\"edges\"][v1]: # иначе - просто добавим v2 в set смежных вершин v1\n",
    "                    data[file][\"edges\"][v1].add(v2)\n",
    "\n",
    "                # аналогично, но относительно вершины v2\n",
    "                if v2 not in data[file][\"edges\"].keys():\n",
    "                    data[file][\"edges\"][v2] = {v1}\n",
    "                elif v1 not in data[file][\"edges\"][v2]:\n",
    "                    data[file][\"edges\"][v2].add(v1)\n",
    "        data[file][\"edges\"] = dict(sorted(data[file][\"edges\"].items())) # отсортируем вершины в словаре (в set для ключа словаря вершины уже отсортированы)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vertex_num': 28,\n",
       " 'edge_num': 210,\n",
       " 'edges': {0: {5, 8, 9, 12, 13, 14, 17, 18, 19, 20, 23, 24, 25, 26, 27},\n",
       "  1: {4, 7, 9, 11, 13, 14, 16, 18, 19, 20, 22, 24, 25, 26, 27},\n",
       "  2: {3, 6, 9, 10, 13, 14, 15, 18, 19, 20, 21, 24, 25, 26, 27},\n",
       "  3: {2, 7, 8, 11, 12, 14, 16, 17, 19, 20, 22, 23, 25, 26, 27},\n",
       "  4: {1, 6, 8, 10, 12, 14, 15, 17, 19, 20, 21, 23, 25, 26, 27},\n",
       "  5: {0, 6, 7, 10, 11, 14, 15, 16, 19, 20, 21, 22, 25, 26, 27},\n",
       "  6: {2, 4, 5, 11, 12, 13, 16, 17, 18, 20, 22, 23, 24, 26, 27},\n",
       "  7: {1, 3, 5, 10, 12, 13, 15, 17, 18, 20, 21, 23, 24, 26, 27},\n",
       "  8: {0, 3, 4, 10, 11, 13, 15, 16, 18, 20, 21, 22, 24, 26, 27},\n",
       "  9: {0, 1, 2, 10, 11, 12, 15, 16, 17, 20, 21, 22, 23, 26, 27},\n",
       "  10: {2, 4, 5, 7, 8, 9, 16, 17, 18, 19, 22, 23, 24, 25, 27},\n",
       "  11: {1, 3, 5, 6, 8, 9, 15, 17, 18, 19, 21, 23, 24, 25, 27},\n",
       "  12: {0, 3, 4, 6, 7, 9, 15, 16, 18, 19, 21, 22, 24, 25, 27},\n",
       "  13: {0, 1, 2, 6, 7, 8, 15, 16, 17, 19, 21, 22, 23, 25, 27},\n",
       "  14: {0, 1, 2, 3, 4, 5, 15, 16, 17, 18, 21, 22, 23, 24, 27},\n",
       "  15: {2, 4, 5, 7, 8, 9, 11, 12, 13, 14, 22, 23, 24, 25, 26},\n",
       "  16: {1, 3, 5, 6, 8, 9, 10, 12, 13, 14, 21, 23, 24, 25, 26},\n",
       "  17: {0, 3, 4, 6, 7, 9, 10, 11, 13, 14, 21, 22, 24, 25, 26},\n",
       "  18: {0, 1, 2, 6, 7, 8, 10, 11, 12, 14, 21, 22, 23, 25, 26},\n",
       "  19: {0, 1, 2, 3, 4, 5, 10, 11, 12, 13, 21, 22, 23, 24, 26},\n",
       "  20: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 21, 22, 23, 24, 25},\n",
       "  21: {2, 4, 5, 7, 8, 9, 11, 12, 13, 14, 16, 17, 18, 19, 20},\n",
       "  22: {1, 3, 5, 6, 8, 9, 10, 12, 13, 14, 15, 17, 18, 19, 20},\n",
       "  23: {0, 3, 4, 6, 7, 9, 10, 11, 13, 14, 15, 16, 18, 19, 20},\n",
       "  24: {0, 1, 2, 6, 7, 8, 10, 11, 12, 14, 15, 16, 17, 19, 20},\n",
       "  25: {0, 1, 2, 3, 4, 5, 10, 11, 12, 13, 15, 16, 17, 18, 20},\n",
       "  26: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 15, 16, 17, 18, 19},\n",
       "  27: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"johnson8-2-4\"] # пример данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {}\n",
    "# data - словарь вида \n",
    "# {\"название датасета\" : [веса вершин в графе], ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in data.keys(): # идём по тест-кейсам\n",
    "    weights[dataset] = [math.ceil(10*i / data[dataset][\"vertex_num\"]) * 0.1 for i in range(1, data[dataset][\"vertex_num\"]+1)] \n",
    "# задаём веса вершин по формуле w_i = ceil(10*i / n) * 0.1, где n - число вершин, i - номер вершины (начиная с 1)\n",
    "# То есть первые 10% вершин имеют вес 0.1, следующие 10% - вес 0.2, ..., последние 10% - вес 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1,\n",
       " 0.1,\n",
       " 0.2,\n",
       " 0.2,\n",
       " 0.2,\n",
       " 0.30000000000000004,\n",
       " 0.30000000000000004,\n",
       " 0.30000000000000004,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.4,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.6000000000000001,\n",
       " 0.6000000000000001,\n",
       " 0.7000000000000001,\n",
       " 0.7000000000000001,\n",
       " 0.7000000000000001,\n",
       " 0.8,\n",
       " 0.8,\n",
       " 0.8,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 0.9,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[\"johnson8-2-4\"] # пример весов вершин"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Реализация алгоритма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomized_max_weighted_clique(edges: dict, weights: list, impact_degree, impact_weight, iterations: int=10) -> list:\n",
    "    \"\"\"\n",
    "    Функция для получения рандомизированного решения задачи о максимальной взвешенной клике.\\n\n",
    "    Parameters:\n",
    "        * edges: словарь смежных вершинам вершин\n",
    "        * weights: список с весами вершин\n",
    "        * impact_degree: степень влиянися количества соседей у вершины на вероятность её выбора в клику\n",
    "        * impact_weight: степень влиянися веса вершины на вероятность её выбора в клику\n",
    "        * iterations: через сколько попыток без улучшения решения выходить из алгоритма\\n\n",
    "    Returns:\n",
    "        * list: данные о найденной взвешенной клике в формате [вес, [вершина в клике 1, ..., вершина в клике k]]\n",
    "    \"\"\"\n",
    "    num_vertices = len(weights) # == len(edges.keys()), число вершин в графе\n",
    "    original_candidates = set(edges.keys()) # set вершин (изначально все являются кандидатами в клику)\n",
    "    original_candidates_degrees = [len(edges[v]) for v in original_candidates] # создаём список степеней вершин (индекс - номер вершины, так как ожидается, что на входе edges остортирован в порядке увеличения номера вершины)\n",
    "\n",
    "    probability_weights = [impact_degree*original_candidates_degrees[v] + impact_weight*weights[v]  for v in edges.keys()] # создаём список с вероятностями выбора вершины в клику в зависимости от (число смежных вершин)*(коэффициент степени вершины) + (вес вершины)*(коэффициент веса вершины)\n",
    "\n",
    "    best_weighted_clique = [] # текущая лучшая взвешенная клика\n",
    "    best_weight = 0 # вес лучшей взвешенной клики\n",
    "\n",
    "    attempts = 0 # текущее число попыток без улучшения результата\n",
    "    while attempts < iterations: # запускаем алгоритм, пока число попыток без изменения результата не превысит счётчик iterations\n",
    "        weighted_clique = [] # создаём \"пустую\" клику\n",
    "        weight = 0 # вес клики на текущей попытке\n",
    "\n",
    "        candidates = original_candidates.copy() # копируем set всех кандидатов\n",
    "        while len(candidates) != 0: # пока есть кандидаты — пытаемся добавить их в клику в зависимости от их probability_weights\n",
    "            candidates_probability_weights = [probability_weights[i] for i in candidates] # обновляем вероятности попадания кандидатов в клику (оставляем вероятности только допустимых вершин) для итерациии случайного выбора\n",
    "            \n",
    "            v = random.choices(population=list(candidates), weights=candidates_probability_weights, k=1)[0] # случайным образом выбираем вершину в клику в соответствии с её вероятнотью (чем больше степень и вес относительно других вершин — тем выше вероятность) (переводим candidates в список для случайного выбора)\n",
    "            weighted_clique.append(v) # добавляем выбранную вершину в клику\n",
    "            weight += weights[v] # увеличиваем вес рассматриваемой клики\n",
    "\n",
    "            candidates = candidates.intersection(edges[v]) # среди кандидитов оставляем только тех, кто смежен со всеми вершинами в текущей клике (итеративно этот список постоянно уменьшается с добавлением новых вершин в клику)\n",
    "\n",
    "        if weight > best_weight: # если нашли новую лучшую взвешенную клику, то запоминаем её\n",
    "            best_weighted_clique = weighted_clique.copy() # сохраняем содержимое лучшей взвешенной клики\n",
    "            best_weight = weight # обновляем лучший вес\n",
    "            # print(f\"attempt {attempts} with new best: {best_weighted_clique}\")\n",
    "            attempts = 0 # обнуляем число итераций без улучшения решения\n",
    "        else:\n",
    "            attempts += 1 # увеличиваем число итераций без улучшения решения\n",
    "\n",
    "    return [best_weight, best_weighted_clique] # возвращаем вес лучшей взвешенной клики и её содержимое"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions = {} \n",
    "# словарь для ответов алгоритма\n",
    "# {\"название датасета\" : \n",
    "#     {\"time\": время на подсчёт,\n",
    "#      \"weight\": вес найденного независимого множества (клики дополнения графа),\n",
    "#      \"independent_set\": [вершины, входящие в независимое множество],\n",
    "#     }\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brock200_1: {'time': 0.11831016999999981, 'weight': 4.5, 'independent_set': [91, 187, 190, 196, 198]}\n",
      "brock200_2: {'time': 0.1617121900000001, 'weight': 7.4, 'independent_set': [56, 112, 152, 157, 164, 187, 188, 193, 196]}\n",
      "brock200_3: {'time': 0.14140774, 'weight': 5.7, 'independent_set': [53, 127, 144, 177, 184, 188, 189]}\n",
      "brock200_4: {'time': 0.12463324, 'weight': 5.3, 'independent_set': [130, 156, 164, 176, 183, 194]}\n",
      "c-fat200-1: {'time': 0.5122809500000003, 'weight': 12.9, 'independent_set': [54, 67, 73, 102, 123, 130, 135, 151, 153, 157, 169, 174, 180, 182, 186, 192, 200]}\n",
      "c-fat200-2: {'time': 0.2980272600000006, 'weight': 7.0, 'independent_set': [58, 86, 124, 144, 170, 172, 174, 182, 186]}\n",
      "c-fat200-5: {'time': 0.10281171999999969, 'weight': 2.9, 'independent_set': [170, 195, 200]}\n",
      "c-fat500-1: {'time': 2.6131518599999994, 'weight': 24.9, 'independent_set': [26, 30, 37, 137, 148, 164, 166, 212, 215, 230, 236, 260, 268, 285, 301, 303, 320, 322, 352, 363, 368, 379, 398, 423, 435, 440, 450, 465, 472, 474, 488, 490, 492, 494, 496, 498]}\n",
      "c-fat500-10: {'time': 0.36884773999999965, 'weight': 3.9, 'independent_set': [421, 457, 471, 483]}\n",
      "c-fat500-2: {'time': 1.2214922099999996, 'weight': 14.4, 'independent_set': [28, 312, 332, 343, 368, 396, 402, 417, 421, 425, 459, 470, 474, 479, 485, 490, 494]}\n",
      "c-fat500-5: {'time': 0.7199774199999993, 'weight': 6.4, 'independent_set': [282, 308, 310, 332, 386, 414, 472, 496]}\n",
      "C125.9: {'time': 0.042337200000000054, 'weight': 3.2, 'independent_set': [58, 90, 105, 122]}\n",
      "gen200_p0.9_44: {'time': 0.06006707000000091, 'weight': 4.0, 'independent_set': [61, 156, 163, 171, 196]}\n",
      "gen200_p0.9_55: {'time': 0.07397271999999902, 'weight': 3.6, 'independent_set': [141, 147, 183, 194]}\n",
      "johnson8-2-4: {'time': 0.04265237999999982, 'weight': 6.5, 'independent_set': [22, 23, 24, 25, 26, 27, 28]}\n",
      "johnson8-4-4: {'time': 0.042346080000000084, 'weight': 5.0, 'independent_set': [66, 67, 68, 69, 70]}\n",
      "johnson16-2-4: {'time': 0.10265003999999892, 'weight': 14.7, 'independent_set': [106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120]}\n",
      "hamming6-2: {'time': 0.018698900000001118, 'weight': 2.0, 'independent_set': [62, 64]}\n",
      "hamming6-4: {'time': 0.10921069999999986, 'weight': 10.4, 'independent_set': [31, 32, 47, 48, 55, 56, 59, 60, 61, 62, 63, 64]}\n",
      "hamming8-2: {'time': 0.047712640000000306, 'weight': 2.0, 'independent_set': [237, 238]}\n",
      "hamming8-4: {'time': 0.1927334700000003, 'weight': 14.4, 'independent_set': [127, 128, 191, 192, 223, 224, 239, 240, 247, 248, 251, 252, 253, 254, 255, 256]}\n",
      "keller4: {'time': 0.1373315599999998, 'weight': 13.0, 'independent_set': [109, 110, 113, 114, 125, 126, 129, 130, 155, 156, 159, 160, 166, 169, 170]}\n",
      "MANN_a9: {'time': 0.01725366000000008, 'weight': 3.0, 'independent_set': [43, 44, 45]}\n",
      "MANN_a27: {'time': 0.0676791300000005, 'weight': 3.0, 'independent_set': [364, 365, 366]}\n",
      "MANN_a45: {'time': 0.28592479, 'weight': 3.0, 'independent_set': [973, 974, 975]}\n",
      "p_hat300-1: {'time': 0.6784068700000006, 'weight': 20.3, 'independent_set': [6, 8, 12, 22, 23, 46, 64, 69, 73, 112, 114, 129, 164, 168, 172, 183, 187, 189, 212, 224, 228, 238, 241, 248, 257, 258, 261, 265, 266, 272, 275, 278, 295]}\n",
      "p_hat300-2: {'time': 0.39757740000000014, 'weight': 15.6, 'independent_set': [15, 16, 69, 99, 113, 132, 157, 158, 167, 194, 202, 207, 228, 236, 238, 242, 248, 249, 261, 265, 278, 284, 289]}\n",
      "p_hat300-3: {'time': 0.1565513199999998, 'weight': 5.2, 'independent_set': [53, 155, 203, 207, 275, 278, 292]}\n",
      "san200_0.7_1: {'time': 0.11964827000000042, 'weight': 5.7, 'independent_set': [57, 135, 158, 162, 186, 189, 191]}\n",
      "san200_0.7_2: {'time': 0.15502118999999936, 'weight': 7.4, 'independent_set': [64, 82, 88, 96, 158, 162, 171, 177, 182, 190]}\n",
      "san200_0.9_1: {'time': 0.061000930000000154, 'weight': 3.1, 'independent_set': [104, 128, 157, 197]}\n",
      "san200_0.9_2: {'time': 0.06616017999999997, 'weight': 3.6, 'independent_set': [113, 190, 192, 199]}\n",
      "san200_0.9_3: {'time': 0.07671878999999962, 'weight': 3.7, 'independent_set': [153, 168, 181, 183]}\n",
      "sanr200_0.7: {'time': 0.10855391000000054, 'weight': 5.0, 'independent_set': [129, 136, 153, 159, 182, 195]}\n"
     ]
    }
   ],
   "source": [
    "for dataset in data.keys(): # идём по тест-кейсам\n",
    "    time_start = time.perf_counter() # замеряем время начала выполнения\n",
    "    for i in range(runs): # делаем runs запусков для усреднения времени\n",
    "        edges_complement = get_complement_edges(data[dataset][\"edges\"]) # переходим к дополнению графа (от независимого множества к клике) (в цикле для честного подсчёта времени)\n",
    "        solution = randomized_max_weighted_clique(edges=edges_complement, weights=weights[dataset], impact_degree=impact_degree, impact_weight=impact_weight, iterations=iterations) # запускаем рандомизированный алгоритм\n",
    "        # print(f\"run: {i}, solution: {solution}\")\n",
    "    time_working = time.perf_counter() - time_start # считаем сколько времени работал алгоритм\n",
    "\n",
    "    check_solution(edges_complement=edges_complement, weights=weights[dataset], solution=solution) # проверка решения (последнего полученного за runs запусков, оно может быть не лучшим)\n",
    "    solution = transform_solution(solution) # сортирует вершины взвешенной клики в порядке возрастания их номера и возвращает нумерацию с единицы\n",
    "    solutions[dataset] = {\"time\": time_working/runs, \"weight\": solution[0], \"independent_set\": solution[1]} # добавление ответа в словарь с ответами\n",
    "    save_solution(dataset, solutions[dataset]) # сохранение полученного ответа\n",
    "    print(f\"{dataset}: {solutions[dataset]}\") # вывод полученного ответа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Documents\\TEMP\\ipykernel_16348\\1291053311.py:83: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  table = pd.concat([table, testcase], ignore_index=True) # объединяем таблицы\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_ff358\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_ff358_level0_col0\" class=\"col_heading level0 col0\" >Instance</th>\n",
       "      <th id=\"T_ff358_level0_col1\" class=\"col_heading level0 col1\" >Time, sec</th>\n",
       "      <th id=\"T_ff358_level0_col2\" class=\"col_heading level0 col2\" >Weight</th>\n",
       "      <th id=\"T_ff358_level0_col3\" class=\"col_heading level0 col3\" >Independent vertices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_ff358_row0_col0\" class=\"data row0 col0\" >brock200_1</td>\n",
       "      <td id=\"T_ff358_row0_col1\" class=\"data row0 col1\" >0.118310</td>\n",
       "      <td id=\"T_ff358_row0_col2\" class=\"data row0 col2\" >4.500000</td>\n",
       "      <td id=\"T_ff358_row0_col3\" class=\"data row0 col3\" >[91, 187, 190, 196, 198]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff358_row1_col0\" class=\"data row1 col0\" >brock200_2</td>\n",
       "      <td id=\"T_ff358_row1_col1\" class=\"data row1 col1\" >0.161712</td>\n",
       "      <td id=\"T_ff358_row1_col2\" class=\"data row1 col2\" >7.400000</td>\n",
       "      <td id=\"T_ff358_row1_col3\" class=\"data row1 col3\" >[56, 112, 152, 157, 164, 187, 188, 193, 196]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff358_row2_col0\" class=\"data row2 col0\" >brock200_3</td>\n",
       "      <td id=\"T_ff358_row2_col1\" class=\"data row2 col1\" >0.141408</td>\n",
       "      <td id=\"T_ff358_row2_col2\" class=\"data row2 col2\" >5.700000</td>\n",
       "      <td id=\"T_ff358_row2_col3\" class=\"data row2 col3\" >[53, 127, 144, 177, 184, 188, 189]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff358_row3_col0\" class=\"data row3 col0\" >brock200_4</td>\n",
       "      <td id=\"T_ff358_row3_col1\" class=\"data row3 col1\" >0.124633</td>\n",
       "      <td id=\"T_ff358_row3_col2\" class=\"data row3 col2\" >5.300000</td>\n",
       "      <td id=\"T_ff358_row3_col3\" class=\"data row3 col3\" >[130, 156, 164, 176, 183, 194]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff358_row4_col0\" class=\"data row4 col0\" >c-fat200-1</td>\n",
       "      <td id=\"T_ff358_row4_col1\" class=\"data row4 col1\" >0.512281</td>\n",
       "      <td id=\"T_ff358_row4_col2\" class=\"data row4 col2\" >12.900000</td>\n",
       "      <td id=\"T_ff358_row4_col3\" class=\"data row4 col3\" >[54, 67, 73, 102, 123, 130, 135, 151, 153, 157, 169, 174, 180, 182, 186, 192, 200]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff358_row5_col0\" class=\"data row5 col0\" >c-fat200-2</td>\n",
       "      <td id=\"T_ff358_row5_col1\" class=\"data row5 col1\" >0.298027</td>\n",
       "      <td id=\"T_ff358_row5_col2\" class=\"data row5 col2\" >7.000000</td>\n",
       "      <td id=\"T_ff358_row5_col3\" class=\"data row5 col3\" >[58, 86, 124, 144, 170, 172, 174, 182, 186]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff358_row6_col0\" class=\"data row6 col0\" >c-fat200-5</td>\n",
       "      <td id=\"T_ff358_row6_col1\" class=\"data row6 col1\" >0.102812</td>\n",
       "      <td id=\"T_ff358_row6_col2\" class=\"data row6 col2\" >2.900000</td>\n",
       "      <td id=\"T_ff358_row6_col3\" class=\"data row6 col3\" >[170, 195, 200]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff358_row7_col0\" class=\"data row7 col0\" >c-fat500-1</td>\n",
       "      <td id=\"T_ff358_row7_col1\" class=\"data row7 col1\" >2.613152</td>\n",
       "      <td id=\"T_ff358_row7_col2\" class=\"data row7 col2\" >24.900000</td>\n",
       "      <td id=\"T_ff358_row7_col3\" class=\"data row7 col3\" >[26, 30, 37, 137, 148, 164, 166, 212, 215, 230, 236, 260, 268, 285, 301, 303, 320, 322, 352, 363, 368, 379, 398, 423, 435, 440, 450, 465, 472, 474, 488, 490, 492, 494, 496, 498]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff358_row8_col0\" class=\"data row8 col0\" >c-fat500-10</td>\n",
       "      <td id=\"T_ff358_row8_col1\" class=\"data row8 col1\" >0.368848</td>\n",
       "      <td id=\"T_ff358_row8_col2\" class=\"data row8 col2\" >3.900000</td>\n",
       "      <td id=\"T_ff358_row8_col3\" class=\"data row8 col3\" >[421, 457, 471, 483]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff358_row9_col0\" class=\"data row9 col0\" >c-fat500-2</td>\n",
       "      <td id=\"T_ff358_row9_col1\" class=\"data row9 col1\" >1.221492</td>\n",
       "      <td id=\"T_ff358_row9_col2\" class=\"data row9 col2\" >14.400000</td>\n",
       "      <td id=\"T_ff358_row9_col3\" class=\"data row9 col3\" >[28, 312, 332, 343, 368, 396, 402, 417, 421, 425, 459, 470, 474, 479, 485, 490, 494]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff358_row10_col0\" class=\"data row10 col0\" >c-fat500-5</td>\n",
       "      <td id=\"T_ff358_row10_col1\" class=\"data row10 col1\" >0.719977</td>\n",
       "      <td id=\"T_ff358_row10_col2\" class=\"data row10 col2\" >6.400000</td>\n",
       "      <td id=\"T_ff358_row10_col3\" class=\"data row10 col3\" >[282, 308, 310, 332, 386, 414, 472, 496]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff358_row11_col0\" class=\"data row11 col0\" >C125.9</td>\n",
       "      <td id=\"T_ff358_row11_col1\" class=\"data row11 col1\" >0.042337</td>\n",
       "      <td id=\"T_ff358_row11_col2\" class=\"data row11 col2\" >3.200000</td>\n",
       "      <td id=\"T_ff358_row11_col3\" class=\"data row11 col3\" >[58, 90, 105, 122]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff358_row12_col0\" class=\"data row12 col0\" >gen200_p0.9_44</td>\n",
       "      <td id=\"T_ff358_row12_col1\" class=\"data row12 col1\" >0.060067</td>\n",
       "      <td id=\"T_ff358_row12_col2\" class=\"data row12 col2\" >4.000000</td>\n",
       "      <td id=\"T_ff358_row12_col3\" class=\"data row12 col3\" >[61, 156, 163, 171, 196]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff358_row13_col0\" class=\"data row13 col0\" >gen200_p0.9_55</td>\n",
       "      <td id=\"T_ff358_row13_col1\" class=\"data row13 col1\" >0.073973</td>\n",
       "      <td id=\"T_ff358_row13_col2\" class=\"data row13 col2\" >3.600000</td>\n",
       "      <td id=\"T_ff358_row13_col3\" class=\"data row13 col3\" >[141, 147, 183, 194]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff358_row14_col0\" class=\"data row14 col0\" >johnson8-2-4</td>\n",
       "      <td id=\"T_ff358_row14_col1\" class=\"data row14 col1\" >0.042652</td>\n",
       "      <td id=\"T_ff358_row14_col2\" class=\"data row14 col2\" >6.500000</td>\n",
       "      <td id=\"T_ff358_row14_col3\" class=\"data row14 col3\" >[22, 23, 24, 25, 26, 27, 28]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff358_row15_col0\" class=\"data row15 col0\" >johnson8-4-4</td>\n",
       "      <td id=\"T_ff358_row15_col1\" class=\"data row15 col1\" >0.042346</td>\n",
       "      <td id=\"T_ff358_row15_col2\" class=\"data row15 col2\" >5.000000</td>\n",
       "      <td id=\"T_ff358_row15_col3\" class=\"data row15 col3\" >[66, 67, 68, 69, 70]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff358_row16_col0\" class=\"data row16 col0\" >johnson16-2-4</td>\n",
       "      <td id=\"T_ff358_row16_col1\" class=\"data row16 col1\" >0.102650</td>\n",
       "      <td id=\"T_ff358_row16_col2\" class=\"data row16 col2\" >14.700000</td>\n",
       "      <td id=\"T_ff358_row16_col3\" class=\"data row16 col3\" >[106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff358_row17_col0\" class=\"data row17 col0\" >hamming6-2</td>\n",
       "      <td id=\"T_ff358_row17_col1\" class=\"data row17 col1\" >0.018699</td>\n",
       "      <td id=\"T_ff358_row17_col2\" class=\"data row17 col2\" >2.000000</td>\n",
       "      <td id=\"T_ff358_row17_col3\" class=\"data row17 col3\" >[62, 64]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff358_row18_col0\" class=\"data row18 col0\" >hamming6-4</td>\n",
       "      <td id=\"T_ff358_row18_col1\" class=\"data row18 col1\" >0.109211</td>\n",
       "      <td id=\"T_ff358_row18_col2\" class=\"data row18 col2\" >10.400000</td>\n",
       "      <td id=\"T_ff358_row18_col3\" class=\"data row18 col3\" >[31, 32, 47, 48, 55, 56, 59, 60, 61, 62, 63, 64]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff358_row19_col0\" class=\"data row19 col0\" >hamming8-2</td>\n",
       "      <td id=\"T_ff358_row19_col1\" class=\"data row19 col1\" >0.047713</td>\n",
       "      <td id=\"T_ff358_row19_col2\" class=\"data row19 col2\" >2.000000</td>\n",
       "      <td id=\"T_ff358_row19_col3\" class=\"data row19 col3\" >[237, 238]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff358_row20_col0\" class=\"data row20 col0\" >hamming8-4</td>\n",
       "      <td id=\"T_ff358_row20_col1\" class=\"data row20 col1\" >0.192733</td>\n",
       "      <td id=\"T_ff358_row20_col2\" class=\"data row20 col2\" >14.400000</td>\n",
       "      <td id=\"T_ff358_row20_col3\" class=\"data row20 col3\" >[127, 128, 191, 192, 223, 224, 239, 240, 247, 248, 251, 252, 253, 254, 255, 256]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff358_row21_col0\" class=\"data row21 col0\" >keller4</td>\n",
       "      <td id=\"T_ff358_row21_col1\" class=\"data row21 col1\" >0.137332</td>\n",
       "      <td id=\"T_ff358_row21_col2\" class=\"data row21 col2\" >13.000000</td>\n",
       "      <td id=\"T_ff358_row21_col3\" class=\"data row21 col3\" >[109, 110, 113, 114, 125, 126, 129, 130, 155, 156, 159, 160, 166, 169, 170]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff358_row22_col0\" class=\"data row22 col0\" >MANN_a9</td>\n",
       "      <td id=\"T_ff358_row22_col1\" class=\"data row22 col1\" >0.017254</td>\n",
       "      <td id=\"T_ff358_row22_col2\" class=\"data row22 col2\" >3.000000</td>\n",
       "      <td id=\"T_ff358_row22_col3\" class=\"data row22 col3\" >[43, 44, 45]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff358_row23_col0\" class=\"data row23 col0\" >MANN_a27</td>\n",
       "      <td id=\"T_ff358_row23_col1\" class=\"data row23 col1\" >0.067679</td>\n",
       "      <td id=\"T_ff358_row23_col2\" class=\"data row23 col2\" >3.000000</td>\n",
       "      <td id=\"T_ff358_row23_col3\" class=\"data row23 col3\" >[364, 365, 366]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff358_row24_col0\" class=\"data row24 col0\" >MANN_a45</td>\n",
       "      <td id=\"T_ff358_row24_col1\" class=\"data row24 col1\" >0.285925</td>\n",
       "      <td id=\"T_ff358_row24_col2\" class=\"data row24 col2\" >3.000000</td>\n",
       "      <td id=\"T_ff358_row24_col3\" class=\"data row24 col3\" >[973, 974, 975]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff358_row25_col0\" class=\"data row25 col0\" >p_hat300-1</td>\n",
       "      <td id=\"T_ff358_row25_col1\" class=\"data row25 col1\" >0.678407</td>\n",
       "      <td id=\"T_ff358_row25_col2\" class=\"data row25 col2\" >20.300000</td>\n",
       "      <td id=\"T_ff358_row25_col3\" class=\"data row25 col3\" >[6, 8, 12, 22, 23, 46, 64, 69, 73, 112, 114, 129, 164, 168, 172, 183, 187, 189, 212, 224, 228, 238, 241, 248, 257, 258, 261, 265, 266, 272, 275, 278, 295]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff358_row26_col0\" class=\"data row26 col0\" >p_hat300-2</td>\n",
       "      <td id=\"T_ff358_row26_col1\" class=\"data row26 col1\" >0.397577</td>\n",
       "      <td id=\"T_ff358_row26_col2\" class=\"data row26 col2\" >15.600000</td>\n",
       "      <td id=\"T_ff358_row26_col3\" class=\"data row26 col3\" >[15, 16, 69, 99, 113, 132, 157, 158, 167, 194, 202, 207, 228, 236, 238, 242, 248, 249, 261, 265, 278, 284, 289]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff358_row27_col0\" class=\"data row27 col0\" >p_hat300-3</td>\n",
       "      <td id=\"T_ff358_row27_col1\" class=\"data row27 col1\" >0.156551</td>\n",
       "      <td id=\"T_ff358_row27_col2\" class=\"data row27 col2\" >5.200000</td>\n",
       "      <td id=\"T_ff358_row27_col3\" class=\"data row27 col3\" >[53, 155, 203, 207, 275, 278, 292]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff358_row28_col0\" class=\"data row28 col0\" >san200_0.7_1</td>\n",
       "      <td id=\"T_ff358_row28_col1\" class=\"data row28 col1\" >0.119648</td>\n",
       "      <td id=\"T_ff358_row28_col2\" class=\"data row28 col2\" >5.700000</td>\n",
       "      <td id=\"T_ff358_row28_col3\" class=\"data row28 col3\" >[57, 135, 158, 162, 186, 189, 191]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff358_row29_col0\" class=\"data row29 col0\" >san200_0.7_2</td>\n",
       "      <td id=\"T_ff358_row29_col1\" class=\"data row29 col1\" >0.155021</td>\n",
       "      <td id=\"T_ff358_row29_col2\" class=\"data row29 col2\" >7.400000</td>\n",
       "      <td id=\"T_ff358_row29_col3\" class=\"data row29 col3\" >[64, 82, 88, 96, 158, 162, 171, 177, 182, 190]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff358_row30_col0\" class=\"data row30 col0\" >san200_0.9_1</td>\n",
       "      <td id=\"T_ff358_row30_col1\" class=\"data row30 col1\" >0.061001</td>\n",
       "      <td id=\"T_ff358_row30_col2\" class=\"data row30 col2\" >3.100000</td>\n",
       "      <td id=\"T_ff358_row30_col3\" class=\"data row30 col3\" >[104, 128, 157, 197]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff358_row31_col0\" class=\"data row31 col0\" >san200_0.9_2</td>\n",
       "      <td id=\"T_ff358_row31_col1\" class=\"data row31 col1\" >0.066160</td>\n",
       "      <td id=\"T_ff358_row31_col2\" class=\"data row31 col2\" >3.600000</td>\n",
       "      <td id=\"T_ff358_row31_col3\" class=\"data row31 col3\" >[113, 190, 192, 199]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff358_row32_col0\" class=\"data row32 col0\" >san200_0.9_3</td>\n",
       "      <td id=\"T_ff358_row32_col1\" class=\"data row32 col1\" >0.076719</td>\n",
       "      <td id=\"T_ff358_row32_col2\" class=\"data row32 col2\" >3.700000</td>\n",
       "      <td id=\"T_ff358_row32_col3\" class=\"data row32 col3\" >[153, 168, 181, 183]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ff358_row33_col0\" class=\"data row33 col0\" >sanr200_0.7</td>\n",
       "      <td id=\"T_ff358_row33_col1\" class=\"data row33 col1\" >0.108554</td>\n",
       "      <td id=\"T_ff358_row33_col2\" class=\"data row33 col2\" >5.000000</td>\n",
       "      <td id=\"T_ff358_row33_col3\" class=\"data row33 col3\" >[129, 136, 153, 159, 182, 195]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1cafaa069a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_results(solutions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Возможные улучшения:**\n",
    "* Пересчёт степеней вершин кандидатов после добавления вершины в клику, чтобы кандидаты, что имели большую степень изначально — в ходе работы алгоритма пересчитывались (чтобы не учитывать \"бесполезные\" связи с вершинами, что не могут попасть в клику)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
